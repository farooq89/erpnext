---
# Source: erpnext/charts/redis-cache/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: release-name-redis-cache
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis-cache
    helm.sh/chart: redis-cache-17.15.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
---
# Source: erpnext/charts/redis-queue/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: release-name-redis-queue
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis-queue
    helm.sh/chart: redis-queue-17.15.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
---
# Source: erpnext/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-erpnext
  labels:

    helm.sh/chart: erpnext-7.0.33
    app.kubernetes.io/name: erpnext
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v15.14.3"
    app.kubernetes.io/managed-by: Helm
---
# Source: erpnext/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.1.6
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  postgres-password: "cG9zdGdyZXM="
  password: "cG9zdGdyZXM="
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: erpnext/templates/secret.yaml
apiVersion: v1
data:
  db-root-password: "cG9zdGdyZXM="
kind: Secret
metadata:
  name: release-name
type: Opaque
---
# Source: erpnext/charts/redis-cache/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis-cache-configuration
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis-cache
    helm.sh/chart: redis-cache-17.15.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  redis.conf: |-
    # User-supplied common configuration:
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly yes
    # Disable RDB persistence, AOF persistence already enabled.
    save ""
    # End of common configuration
  master.conf: |-
    dir /data
    # User-supplied master configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of master configuration
  replica.conf: |-
    dir /data
    # User-supplied replica configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of replica configuration
---
# Source: erpnext/charts/redis-cache/templates/health-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis-cache-health
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis-cache
    helm.sh/chart: redis-cache-17.15.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  ping_readiness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ] && [ "$responseFirstWord" != "MASTERDOWN" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
    exit $exit_status
  ping_liveness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
    exit $exit_status
---
# Source: erpnext/charts/redis-cache/templates/scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis-cache-scripts
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis-cache
    helm.sh/chart: redis-cache-17.15.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  start-master.sh: |
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    if [[ -f /opt/bitnami/redis/mounted-etc/master.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
    fi
    if [[ -f /opt/bitnami/redis/mounted-etc/redis.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
    fi
    ARGS=("--port" "${REDIS_PORT}")
    ARGS+=("--protected-mode" "no")
    ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
    ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
    exec redis-server "${ARGS[@]}"
---
# Source: erpnext/charts/redis-queue/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis-queue-configuration
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis-queue
    helm.sh/chart: redis-queue-17.15.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  redis.conf: |-
    # User-supplied common configuration:
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly yes
    # Disable RDB persistence, AOF persistence already enabled.
    save ""
    # End of common configuration
  master.conf: |-
    dir /data
    # User-supplied master configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of master configuration
  replica.conf: |-
    dir /data
    # User-supplied replica configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of replica configuration
---
# Source: erpnext/charts/redis-queue/templates/health-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis-queue-health
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis-queue
    helm.sh/chart: redis-queue-17.15.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  ping_readiness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ] && [ "$responseFirstWord" != "MASTERDOWN" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
    exit $exit_status
  ping_liveness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
    exit $exit_status
---
# Source: erpnext/charts/redis-queue/templates/scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis-queue-scripts
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis-queue
    helm.sh/chart: redis-queue-17.15.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  start-master.sh: |
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    if [[ -f /opt/bitnami/redis/mounted-etc/master.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
    fi
    if [[ -f /opt/bitnami/redis/mounted-etc/redis.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
    fi
    ARGS=("--port" "${REDIS_PORT}")
    ARGS+=("--protected-mode" "no")
    ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
    ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
    exec redis-server "${ARGS[@]}"
---
# Source: erpnext/templates/pvc.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  labels:
    app: erpnext
    chart: erpnext-7.0.33
    heritage: Helm
    release: release-name
  name: release-name-erpnext
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: "20Gi"
  storageClassName: managed-csi
---
# Source: erpnext/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql-hl
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.1.6
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: primary
---
# Source: erpnext/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.1.6
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
  annotations:
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: primary
---
# Source: erpnext/charts/redis-cache/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-redis-cache-headless
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis-cache
    helm.sh/chart: redis-cache-17.15.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
  annotations:
    
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
  selector:
    app.kubernetes.io/name: redis-cache
    app.kubernetes.io/instance: release-name
---
# Source: erpnext/charts/redis-cache/templates/master/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-redis-cache-master
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis-cache
    helm.sh/chart: redis-cache-17.15.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: master
spec:
  type: ClusterIP
  internalTrafficPolicy: Cluster
  sessionAffinity: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
      nodePort: null
  selector:
    app.kubernetes.io/name: redis-cache
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: master
---
# Source: erpnext/charts/redis-queue/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-redis-queue-headless
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis-queue
    helm.sh/chart: redis-queue-17.15.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
  annotations:
    
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
  selector:
    app.kubernetes.io/name: redis-queue
    app.kubernetes.io/instance: release-name
---
# Source: erpnext/charts/redis-queue/templates/master/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-redis-queue-master
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis-queue
    helm.sh/chart: redis-queue-17.15.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: master
spec:
  type: ClusterIP
  internalTrafficPolicy: Cluster
  sessionAffinity: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
      nodePort: null
  selector:
    app.kubernetes.io/name: redis-queue
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: master
---
# Source: erpnext/templates/service-gunicorn.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-erpnext-gunicorn
  labels:
    helm.sh/chart: erpnext-7.0.33
    app.kubernetes.io/name: erpnext
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v15.14.3"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8000
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: erpnext-gunicorn
    app.kubernetes.io/instance: release-name-gunicorn
---
# Source: erpnext/templates/service-nginx.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-erpnext
  labels:
    helm.sh/chart: erpnext-7.0.33
    app.kubernetes.io/name: erpnext
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v15.14.3"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: erpnext-nginx
    app.kubernetes.io/instance: release-name-nginx
---
# Source: erpnext/templates/service-socketio.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-erpnext-socketio
  labels:
    helm.sh/chart: erpnext-7.0.33
    app.kubernetes.io/name: erpnext
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v15.14.3"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 9000
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: erpnext-socketio
    app.kubernetes.io/instance: release-name-socketio
---
# Source: erpnext/templates/deployment-gunicorn.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-erpnext-gunicorn
  labels:
    helm.sh/chart: erpnext-7.0.33
    app.kubernetes.io/name: erpnext
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v15.14.3"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: erpnext-gunicorn
      app.kubernetes.io/instance: release-name-gunicorn
  template:
    metadata:
      labels:
        app.kubernetes.io/name: erpnext-gunicorn
        app.kubernetes.io/instance: release-name-gunicorn
    spec:
      serviceAccountName: release-name-erpnext
      securityContext:
        supplementalGroups:
        - 1000
      containers:
        - name: gunicorn
          args:
            []
          securityContext:
            capabilities:
              add:
              - CAP_CHOWN
          image: "usman89/myrepo:frapee_atd_0.0.1"
          imagePullPolicy: Always
          volumeMounts:
          - name: sites-dir
            mountPath: /home/frappe/frappe-bench/sites
          - name: logs
            mountPath: /home/frappe/frappe-bench/logs
          ports:
            - name: http
              containerPort: 8000
              protocol: TCP
          livenessProbe:
            initialDelaySeconds: 5
            periodSeconds: 10
            tcpSocket:
              port: 8000
          readinessProbe:
            initialDelaySeconds: 5
            periodSeconds: 10
            tcpSocket:
              port: 8000
          resources:
            {}
      volumes:
        - name: sites-dir
          persistentVolumeClaim:
            claimName: release-name-erpnext
            readOnly: false
        - name: logs
          emptyDir: {}
      tolerations:
        - effect: NoSchedule
          key: CriticalAddonsOnly
          operator: Equal
          value: "true"
---
# Source: erpnext/templates/deployment-nginx.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-erpnext-nginx
  labels:
    helm.sh/chart: erpnext-7.0.33
    app.kubernetes.io/name: erpnext
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v15.14.3"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: erpnext-nginx
      app.kubernetes.io/instance: release-name-nginx
  template:
    metadata:
      labels:
        app.kubernetes.io/name: erpnext-nginx
        app.kubernetes.io/instance: release-name-nginx
    spec:
      serviceAccountName: release-name-erpnext
      securityContext:
        supplementalGroups:
        - 1000
      containers:
        - name: nginx
          args:
          - nginx-entrypoint.sh
          env:
            - name: "BACKEND"
              value: release-name-erpnext-gunicorn:8000
            - name: "SOCKETIO"
              value: release-name-erpnext-socketio:9000
            - name: "UPSTREAM_REAL_IP_ADDRESS"
              value: "127.0.0.1"
            - name: "UPSTREAM_REAL_IP_RECURSIVE"
              value: "on"
            - name: "UPSTREAM_REAL_IP_HEADER"
              value: X-Forwarded-For
            - name: "FRAPPE_SITE_NAME_HEADER"
              value: k8-atd.mmis.space
          image: "usman89/myrepo:frapee_atd_0.0.1"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          livenessProbe:
            initialDelaySeconds: 5
            periodSeconds: 10
            tcpSocket:
              port: 8080
          readinessProbe:
            initialDelaySeconds: 5
            periodSeconds: 10
            tcpSocket:
              port: 8080
          resources:
            {}
          securityContext:
            capabilities:
              add:
              - CAP_CHOWN
          volumeMounts:
          - name: sites-dir
            mountPath: /home/frappe/frappe-bench/sites
      volumes:
        - name: sites-dir
          persistentVolumeClaim:
            claimName: release-name-erpnext
            readOnly: false
      tolerations:
        - effect: NoSchedule
          key: CriticalAddonsOnly
          operator: Equal
          value: "true"
---
# Source: erpnext/templates/deployment-scheduler.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-erpnext-scheduler
  labels:
    helm.sh/chart: erpnext-7.0.33
    app.kubernetes.io/name: erpnext
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v15.14.3"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: erpnext-scheduler
      app.kubernetes.io/instance: release-name-scheduler
  template:
    metadata:
      labels:
        app.kubernetes.io/name: erpnext-scheduler
        app.kubernetes.io/instance: release-name-scheduler
    spec:
      serviceAccountName: release-name-erpnext
      securityContext:
        supplementalGroups:
        - 1000
      containers:
        - name: scheduler
          args:
          - bench
          - schedule
          image: "usman89/myrepo:frapee_atd_0.0.1"
          imagePullPolicy: Always
          livenessProbe:
            
            exec:
              command:
                - bash
                - -c
                - echo "Ping backing services";
                - wait-for-it release-name-postgresql:5432 -t 1;
            initialDelaySeconds: 15
            periodSeconds: 5
            
          readinessProbe:
            
            exec:
              command:
                - bash
                - -c
                - echo "Ping backing services";
                - wait-for-it release-name-postgresql:5432 -t 1;
            initialDelaySeconds: 15
            periodSeconds: 5
            
          resources:
            {}
          securityContext:
            capabilities:
              add:
              - CAP_CHOWN
          volumeMounts:
          - name: sites-dir
            mountPath: /home/frappe/frappe-bench/sites
          - name: logs
            mountPath: /home/frappe/frappe-bench/logs
      volumes:
        - name: sites-dir
          persistentVolumeClaim:
            claimName: release-name-erpnext
            readOnly: false
        - name: logs
          emptyDir: {}
      tolerations:
        - effect: NoSchedule
          key: CriticalAddonsOnly
          operator: Equal
          value: "true"
---
# Source: erpnext/templates/deployment-socketio.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-erpnext-socketio
  labels:
    helm.sh/chart: erpnext-7.0.33
    app.kubernetes.io/name: erpnext
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v15.14.3"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: erpnext-socketio
      app.kubernetes.io/instance: release-name-socketio
  template:
    metadata:
      labels:
        app.kubernetes.io/name: erpnext-socketio
        app.kubernetes.io/instance: release-name-socketio
    spec:
      serviceAccountName: release-name-erpnext
      securityContext:
        supplementalGroups:
        - 1000
      containers:
        - name: socketio
          args:
            - node
            - /home/frappe/frappe-bench/apps/frappe/socketio.js
          securityContext:
            capabilities:
              add:
              - CAP_CHOWN
          image: "usman89/myrepo:frapee_atd_0.0.1"
          volumeMounts:
          - name: sites-dir
            mountPath: /home/frappe/frappe-bench/sites
          - name: logs
            mountPath: /home/frappe/frappe-bench/logs
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 9000
              protocol: TCP
          livenessProbe:
            initialDelaySeconds: 5
            periodSeconds: 10
            tcpSocket:
              port: 9000
          readinessProbe:
            initialDelaySeconds: 5
            periodSeconds: 10
            tcpSocket:
              port: 9000
          resources:
            {}
      volumes:
        - name: sites-dir
          persistentVolumeClaim:
            claimName: release-name-erpnext
            readOnly: false
        - name: logs
          emptyDir: {}
      tolerations:
        - effect: NoSchedule
          key: CriticalAddonsOnly
          operator: Equal
          value: "true"
---
# Source: erpnext/templates/deployment-worker-default.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-erpnext-worker-d
  labels:
    helm.sh/chart: erpnext-7.0.33
    app.kubernetes.io/name: erpnext
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v15.14.3"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: erpnext-worker-d
      app.kubernetes.io/instance: release-name-worker-d
  template:
    metadata:
      labels:
        app.kubernetes.io/name: erpnext-worker-d
        app.kubernetes.io/instance: release-name-worker-d
    spec:
      serviceAccountName: release-name-erpnext
      securityContext:
        supplementalGroups:
        - 1000
      containers:
        - name: default
          args:
          - bench
          - worker
          - --queue
          - default
          image: "usman89/myrepo:frapee_atd_0.0.1"
          imagePullPolicy: Always
          livenessProbe:
            
            exec:
              command:
                - bash
                - -c
                - echo "Ping backing services";
                - wait-for-it release-name-postgresql:5432 -t 1;
            initialDelaySeconds: 15
            periodSeconds: 5
            
          readinessProbe:
            
            exec:
              command:
                - bash
                - -c
                - echo "Ping backing services";
                - wait-for-it release-name-postgresql:5432 -t 1;
            initialDelaySeconds: 15
            periodSeconds: 5
            
          resources:
            {}
          securityContext:
            capabilities:
              add:
              - CAP_CHOWN
          volumeMounts:
          - name: sites-dir
            mountPath: /home/frappe/frappe-bench/sites
          - name: logs
            mountPath: /home/frappe/frappe-bench/logs
      volumes:
        - name: sites-dir
          persistentVolumeClaim:
            claimName: release-name-erpnext
            readOnly: false
        - name: logs
          emptyDir: {}
      tolerations:
        - effect: NoSchedule
          key: CriticalAddonsOnly
          operator: Equal
          value: "true"
---
# Source: erpnext/templates/deployment-worker-long.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-erpnext-worker-l
  labels:
    helm.sh/chart: erpnext-7.0.33
    app.kubernetes.io/name: erpnext
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v15.14.3"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: erpnext-worker-l
      app.kubernetes.io/instance: release-name-worker-l
  template:
    metadata:
      labels:
        app.kubernetes.io/name: erpnext-worker-l
        app.kubernetes.io/instance: release-name-worker-l
    spec:
      serviceAccountName: release-name-erpnext
      securityContext:
        supplementalGroups:
        - 1000
      containers:
        - name: long
          args:
          - bench
          - worker
          - --queue
          - long,default,short
          image: "usman89/myrepo:frapee_atd_0.0.1"
          imagePullPolicy: Always
          livenessProbe:
            
            exec:
              command:
                - bash
                - -c
                - echo "Ping backing services";
                - wait-for-it release-name-postgresql:5432 -t 1;
            initialDelaySeconds: 15
            periodSeconds: 5
            
          readinessProbe:
            
            exec:
              command:
                - bash
                - -c
                - echo "Ping backing services";
                - wait-for-it release-name-postgresql:5432 -t 1;
            initialDelaySeconds: 15
            periodSeconds: 5
            
          resources:
            {}
          securityContext:
            capabilities:
              add:
              - CAP_CHOWN
          volumeMounts:
          - name: sites-dir
            mountPath: /home/frappe/frappe-bench/sites
          - name: logs
            mountPath: /home/frappe/frappe-bench/logs
      volumes:
        - name: sites-dir
          persistentVolumeClaim:
            claimName: release-name-erpnext
            readOnly: false
        - name: logs
          emptyDir: {}
      tolerations:
        - effect: NoSchedule
          key: CriticalAddonsOnly
          operator: Equal
          value: "true"
---
# Source: erpnext/templates/deployment-worker-short.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-erpnext-worker-s
  labels:
    helm.sh/chart: erpnext-7.0.33
    app.kubernetes.io/name: erpnext
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v15.14.3"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: erpnext-worker-s
      app.kubernetes.io/instance: release-name-worker-s
  template:
    metadata:
      labels:
        app.kubernetes.io/name: erpnext-worker-s
        app.kubernetes.io/instance: release-name-worker-s
    spec:
      serviceAccountName: release-name-erpnext
      securityContext:
        supplementalGroups:
        - 1000
      containers:
        - name: short
          args:
          - bench
          - worker
          - --queue
          - short,default
          image: "usman89/myrepo:frapee_atd_0.0.1"
          imagePullPolicy: Always
          livenessProbe:
            
            exec:
              command:
                - bash
                - -c
                - echo "Ping backing services";
                - wait-for-it release-name-postgresql:5432 -t 1;
            initialDelaySeconds: 15
            periodSeconds: 5
            
          readinessProbe:
            
            exec:
              command:
                - bash
                - -c
                - echo "Ping backing services";
                - wait-for-it release-name-postgresql:5432 -t 1;
            initialDelaySeconds: 15
            periodSeconds: 5
            
          resources:
            {}
          securityContext:
            capabilities:
              add:
              - CAP_CHOWN
          volumeMounts:
          - name: sites-dir
            mountPath: /home/frappe/frappe-bench/sites
          - name: logs
            mountPath: /home/frappe/frappe-bench/logs
      volumes:
        - name: sites-dir
          persistentVolumeClaim:
            claimName: release-name-erpnext
            readOnly: false
        - name: logs
          emptyDir: {}
      tolerations:
        - effect: NoSchedule
          key: CriticalAddonsOnly
          operator: Equal
          value: "true"
---
# Source: erpnext/templates/hpa-gunicorn.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: release-name-erpnext-gunicorn
  labels:
    helm.sh/chart: erpnext-7.0.33
    app.kubernetes.io/name: erpnext
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v15.14.3"
    app.kubernetes.io/managed-by: Helm
spec:
  scaleTargetRef:
    apiVersion: apps/v2
    kind: Deployment
    name: release-name-erpnext-gunicorn
  minReplicas: 1
  maxReplicas: 3
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 75
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 75
---
# Source: erpnext/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.1.6
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
  annotations:
spec:
  replicas: 1
  serviceName: release-name-postgresql-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: release-name-postgresql
      labels:
        app.kubernetes.io/name: postgresql
        helm.sh/chart: postgresql-12.1.6
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: primary
      annotations:
    spec:
      serviceAccountName: default
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      tolerations:
        - effect: NoSchedule
          key: CriticalAddonsOnly
          operator: Equal
          value: "true"
      securityContext:
        fsGroup: 1001
      hostNetwork: false
      hostIPC: false
      initContainers:
      containers:
        - name: postgresql
          image: docker.io/postgres:14.11
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "true"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: postgres-password
            - name: POSTGRES_DB
              value: "postgres123"
            # Replication
            # Initdb
            # Standby
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "postgres" -d "dbname=postgres123" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                
                - |
                  exec pg_isready -U "postgres" -d "dbname=postgres123" -h 127.0.0.1 -p 5432
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
        storageClassName: managed-csi
---
# Source: erpnext/charts/redis-cache/templates/master/application.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-redis-cache-master
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis-cache
    helm.sh/chart: redis-cache-17.15.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: master
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: redis-cache
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: master
  serviceName: release-name-redis-cache-headless
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: redis-cache
        helm.sh/chart: redis-cache-17.15.2
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: master
      annotations:
        checksum/configmap: 86bcc953bb473748a3d3dc60b7c11f34e60c93519234d4c37f42e22ada559d47
        checksum/health: aff24913d801436ea469d8d374b2ddb3ec4c43ee7ab24663d5f8ff1a1b6991a9
        checksum/scripts: 43cdf68c28f3abe25ce017a82f74dbf2437d1900fd69df51a55a3edf6193d141
        checksum/secret: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
    spec:
      
      securityContext:
        fsGroup: 1001
      serviceAccountName: release-name-redis-cache
      automountServiceAccountToken: true
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: redis-cache
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: master
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      tolerations:
        - effect: NoSchedule
          key: CriticalAddonsOnly
          operator: Equal
          value: "true"
      terminationGracePeriodSeconds: 30
      containers:
        - name: redis
          image: docker.io/bitnami/redis:7.0.12-debian-11-r19
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            runAsGroup: 0
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          command:
            - /bin/bash
          args:
            - -c
            - /opt/bitnami/scripts/start-scripts/start-master.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: REDIS_REPLICATION_MODE
              value: master
            - name: ALLOW_EMPTY_PASSWORD
              value: "yes"
            - name: REDIS_TLS_ENABLED
              value: "no"
            - name: REDIS_PORT
              value: "6379"
          ports:
            - name: redis
              containerPort: 6379
          livenessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            # One second longer than command timeout should prevent generation of zombie processes.
            timeoutSeconds: 6
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_liveness_local.sh 5
          readinessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            timeoutSeconds: 2
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_readiness_local.sh 1
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: start-scripts
              mountPath: /opt/bitnami/scripts/start-scripts
            - name: health
              mountPath: /health
            - name: redis-data
              mountPath: /data
            - name: config
              mountPath: /opt/bitnami/redis/mounted-etc
            - name: redis-tmp-conf
              mountPath: /opt/bitnami/redis/etc/
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: start-scripts
          configMap:
            name: release-name-redis-cache-scripts
            defaultMode: 0755
        - name: health
          configMap:
            name: release-name-redis-cache-health
            defaultMode: 0755
        - name: config
          configMap:
            name: release-name-redis-cache-configuration
        - name: redis-tmp-conf
          emptyDir: {}
        - name: tmp
          emptyDir: {}
        - name: redis-data
          emptyDir: {}
---
# Source: erpnext/charts/redis-queue/templates/master/application.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-redis-queue-master
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis-queue
    helm.sh/chart: redis-queue-17.15.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: master
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: redis-queue
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: master
  serviceName: release-name-redis-queue-headless
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: redis-queue
        helm.sh/chart: redis-queue-17.15.2
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: master
      annotations:
        checksum/configmap: 86bcc953bb473748a3d3dc60b7c11f34e60c93519234d4c37f42e22ada559d47
        checksum/health: aff24913d801436ea469d8d374b2ddb3ec4c43ee7ab24663d5f8ff1a1b6991a9
        checksum/scripts: 43cdf68c28f3abe25ce017a82f74dbf2437d1900fd69df51a55a3edf6193d141
        checksum/secret: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
    spec:
      
      securityContext:
        fsGroup: 1001
      serviceAccountName: release-name-redis-queue
      automountServiceAccountToken: true
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: redis-queue
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: master
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      tolerations:
        - effect: NoSchedule
          key: CriticalAddonsOnly
          operator: Equal
          value: "true"
      terminationGracePeriodSeconds: 30
      containers:
        - name: redis
          image: docker.io/bitnami/redis:7.0.12-debian-11-r19
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            runAsGroup: 0
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          command:
            - /bin/bash
          args:
            - -c
            - /opt/bitnami/scripts/start-scripts/start-master.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: REDIS_REPLICATION_MODE
              value: master
            - name: ALLOW_EMPTY_PASSWORD
              value: "yes"
            - name: REDIS_TLS_ENABLED
              value: "no"
            - name: REDIS_PORT
              value: "6379"
          ports:
            - name: redis
              containerPort: 6379
          livenessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            # One second longer than command timeout should prevent generation of zombie processes.
            timeoutSeconds: 6
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_liveness_local.sh 5
          readinessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            timeoutSeconds: 2
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_readiness_local.sh 1
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: start-scripts
              mountPath: /opt/bitnami/scripts/start-scripts
            - name: health
              mountPath: /health
            - name: redis-data
              mountPath: /data
            - name: config
              mountPath: /opt/bitnami/redis/mounted-etc
            - name: redis-tmp-conf
              mountPath: /opt/bitnami/redis/etc/
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: start-scripts
          configMap:
            name: release-name-redis-queue-scripts
            defaultMode: 0755
        - name: health
          configMap:
            name: release-name-redis-queue-health
            defaultMode: 0755
        - name: config
          configMap:
            name: release-name-redis-queue-configuration
        - name: redis-tmp-conf
          emptyDir: {}
        - name: tmp
          emptyDir: {}
        - name: redis-data
          emptyDir: {}
---
# Source: erpnext/templates/job-configure-bench.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-erpnext-conf-bench-20240326213124
  labels:
    helm.sh/chart: erpnext-7.0.33
    app.kubernetes.io/name: erpnext
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v15.14.3"
    app.kubernetes.io/managed-by: Helm
spec:
  backoffLimit: 0
  template:
    spec:
      serviceAccountName: release-name-erpnext
      initContainers:
      - name: frappe-bench-ownership
        image: usman89/myrepo:frapee_atd_0.0.1
        imagePullPolicy: Always
        command: ['sh', '-c']
        args:
          - chown -R "1000:1000" /home/frappe/frappe-bench/sites /home/frappe/frappe-bench/logs
        resources:
          {}
        securityContext:
          # run as root to set ownership
          runAsUser: 0
        volumeMounts:
          - name: sites-dir
            mountPath: /home/frappe/frappe-bench/sites
          - name: logs
            mountPath: /home/frappe/frappe-bench/logs
      securityContext:
        supplementalGroups:
        - 1000
      containers:
      - name: configure
        image: "usman89/myrepo:frapee_atd_0.0.1"
        imagePullPolicy: Always
        command:
          - bash
          - -c
        args:
          - >
            ls -1 apps > sites/apps.txt;
            [[ -f sites/common_site_config.json ]] || echo "{}" > sites/common_site_config.json;
            bench set-config -gp db_port $DB_PORT;
            bench set-config -g db_host $DB_HOST;
            bench set-config -g redis_cache $REDIS_CACHE;
            bench set-config -g redis_queue $REDIS_QUEUE;
            bench set-config -gp socketio_port $SOCKETIO_PORT;
        env:
          - name: DB_HOST
            value: 
          - name: DB_PORT
            value: "3306"
          - name: REDIS_CACHE
            value: redis://release-name-redis-cache-master:6379
          - name: REDIS_QUEUE
            value: redis://release-name-redis-queue-master:6379
          - name: SOCKETIO_PORT
            value: "9000"
        resources:
          {}
        volumeMounts:
          - name: sites-dir
            mountPath: /home/frappe/frappe-bench/sites
          - name: logs
            mountPath: /home/frappe/frappe-bench/logs
      restartPolicy: Never
      volumes:
        - name: sites-dir
          persistentVolumeClaim:
            claimName: release-name-erpnext
            readOnly: false
        - name: logs
          emptyDir: {}
      tolerations:
        - effect: NoSchedule
          key: CriticalAddonsOnly
          operator: Equal
          value: "true"
---
# Source: erpnext/templates/job-create-site.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-erpnext-new-site-20240326213124
  labels:
    helm.sh/chart: erpnext-7.0.33
    app.kubernetes.io/name: erpnext
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v15.14.3"
    app.kubernetes.io/managed-by: Helm
spec:
  backoffLimit: 0
  template:
    spec:
      serviceAccountName: release-name-erpnext
      securityContext:
        supplementalGroups:
        - 1000
      initContainers:
        - name: validate-config
          image: "usman89/myrepo:frapee_atd_0.0.1"
          imagePullPolicy: Always
          command: ["bash", "-c"]
          args:
            - >
            - set -x;
              export start=`date +%s`;
              until [[ -n `grep -hs ^ sites/common_site_config.json | jq -r ".db_host // empty"` ]] && \
                [[ -n `grep -hs ^ sites/common_site_config.json | jq -r ".redis_cache // empty"` ]] && \
                [[ -n `grep -hs ^ sites/common_site_config.json | jq -r ".redis_queue // empty"` ]];
              do
                echo "Waiting for sites/common_site_config.json to be created";
                sleep 5;
                if (( `date +%s`-start > 600 )); then
                  echo "could not find sites/common_site_config.json with required keys";
                  exit 1
                fi
              done;
              echo "sites/common_site_config.json found";
              ls;
              pwd;
          resources:
            {}
          securityContext:
            capabilities:
              add:
              - CAP_CHOWN
          volumeMounts:
            - name: sites-dir
              mountPath: /home/frappe/frappe-bench/sites
      containers:
      - name: create-site
        image: "usman89/myrepo:frapee_atd_0.0.1"
        imagePullPolicy: Always
        command: ["bash", "-c"]
        args:
          - >
            bench new-site $(SITE_NAME)
            --db-type=$(DB_TYPE)
            --db-host=$(DB_HOST)
            --db-port=$(DB_PORT)
            --admin-password=$(ADMIN_PASSWORD)
            --mariadb-root-username=$(DB_ROOT_USER)
            --mariadb-root-password=$(DB_ROOT_PASSWORD)
            --install-app=associated_terminals
            --force
            ;rm -f currentsite.txt
        env:
          - name: "SITE_NAME"
            value: "k8-atd.mmis.space"
          - name: "DB_TYPE"
            value: postgres
          - name: "DB_HOST"
            value: release-name-postgresql
          - name: "DB_PORT"
            value: "5432"
          - name: "DB_ROOT_USER"
            value: "postgres"
          - name: "DB_ROOT_PASSWORD"
            valueFrom:
              secretKeyRef:
                key:  db-root-password
                name: release-name
          - name: "ADMIN_PASSWORD"
            value: "mm@123"
        resources:
          {}
        securityContext:
          capabilities:
            add:
            - CAP_CHOWN
        volumeMounts:
          - name: sites-dir
            mountPath: /home/frappe/frappe-bench/sites
          - name: logs
            mountPath: /home/frappe/frappe-bench/logs
      restartPolicy: Never
      volumes:
        - name: sites-dir
          persistentVolumeClaim:
            claimName: release-name-erpnext
            readOnly: false
        - name: logs
          emptyDir: {}
      tolerations:
        - effect: NoSchedule
          key: CriticalAddonsOnly
          operator: Equal
          value: "true"
---
# Source: erpnext/templates/job-migrate-site.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-erpnext-migrate-20240326213124
  labels:
    helm.sh/chart: erpnext-7.0.33
    app.kubernetes.io/name: erpnext
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v15.14.3"
    app.kubernetes.io/managed-by: Helm
spec:
  backoffLimit: 0
  template:
    spec:
      serviceAccountName: release-name-erpnext
      securityContext:
        supplementalGroups:
        - 1000
      containers:
      - name: migrate
        image: "usman89/myrepo:frapee_atd_0.0.1"
        imagePullPolicy: Always
        command: ["bash", "-c"]
        args:
          - >
            cd apps;
            git clone https://x-token-auth:ATCTT3xFfGN01ZGPAktgG5e_SQ02ryC4NimdhgBHl57h0aQ0xsEdNyfyOytjlnCok-ErgKPeyRh24Kw31KtDNKVYxTMeaKNQj0sZL2ze8FGCJgNkbqCzXq_-lMU248UkkdGbOWo-4pVSSIYUDI1WnmpR5UYvO_GqwWys-8QmJcBGxm1M-6lKBnY=39B560F8@bitbucket.org/persona-lworkspace/associated-terminals.git;
            cd associated-terminals;
            cp -r .git /home/frappe/frappe-bench/apps/associated_terminals;
            cd ..;
            cd associated_terminals;
            git stash;
            git pull;
            yarn build;
            cd ../..;
            sleep 90;
            bench --site k8-atd.mmis.space migrate
        env:
          - name: "SITE_NAME"
            value: "k8-atd.mmis.space"
        resources:
          {}
        securityContext:
          capabilities:
            add:
            - CAP_CHOWN
        volumeMounts:
          - name: sites-dir
            mountPath: /home/frappe/frappe-bench/sites
          - name: logs
            mountPath: /home/frappe/frappe-bench/logs
      restartPolicy: Never
      volumes:
        - name: sites-dir
          persistentVolumeClaim:
            claimName: release-name-erpnext
            readOnly: false
        - name: logs
          emptyDir: {}
      tolerations:
        - effect: NoSchedule
          key: CriticalAddonsOnly
          operator: Equal
          value: "true"
---
# Source: erpnext/templates/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: dev-erp-ingress
  labels:
    helm.sh/chart: erpnext-7.0.33
    app.kubernetes.io/name: erpnext
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v15.14.3"
    app.kubernetes.io/managed-by: Helm
  annotations:
    kubernetes.io/ingress.class: nginx
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - "k8-atd.mmis.space"
      secretName: ingress-cert
  rules:
    - host: "k8-atd.mmis.space"
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: release-name-erpnext
                port:
                  number: 8080
---
# Source: erpnext/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "release-name-erpnext-test-connection"
  labels:

    helm.sh/chart: erpnext-7.0.33
    app.kubernetes.io/name: erpnext
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v15.14.3"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test-success
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args:  ['release-name-erpnext:8080']
  restartPolicy: Never
